{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505625dd",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfe56be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os \n",
    "from tensorflow.keras.layers import Dense , Conv2D, MaxPooling2D , Flatten , Input \n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dde216",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('F:/facial-Verification')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1d247",
   "metadata": {},
   "source": [
    "# load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8a137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_images = tf.data.Dataset.list_files(os.path.join(os.getcwd() , 'data' , 'positive' , '*.jpg')).take(1000)\n",
    "negative_images = tf.data.Dataset.list_files(os.path.join(os.getcwd() , 'data' , 'negative' , '*.jpg')).take(1000)\n",
    "anchors_images = tf.data.Dataset.list_files(os.path.join(os.getcwd() , 'data' , 'anchors' , '*.jpg')).take(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess( anchor_path ,img_path  , label) : \n",
    "    # load anchor \n",
    "    anchor = tf.io.read_file(anchor_path ) \n",
    "    anchor_img = tf.io.decode_jpeg(anchor) \n",
    "    anchor_img = tf.image.resize(anchor_img  , (100 ,100))\n",
    "    \n",
    "    # load the image \n",
    "    img = tf.io.read_file(img_path) \n",
    "    img = tf.io.decode_jpeg(img) \n",
    "    img = tf.image.resize(img , (100 , 100))\n",
    "     \n",
    "    \n",
    "    return anchor_img , img , label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b0afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_ds = tf.data.Dataset.zip(( anchors_images ,positive_images  , tf.data.Dataset.from_tensor_slices(tf.ones(len(positive_images)))))\n",
    "negative_ds = tf.data.Dataset.zip(( anchors_images ,negative_images  , tf.data.Dataset.from_tensor_slices(tf.zeros(len(positive_images)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b9f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = positive_ds.concatenate(negative_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82faa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.map(preprocess).cache().shuffle(1000)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e44ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds.take(int(round(len(ds) * .75))) \n",
    "val_ds = ds.skip(int(round(len(ds) * .75)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250123a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(16).prefetch(8)\n",
    "val_ds = val_ds.batch(16).prefetch(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42620468",
   "metadata": {},
   "source": [
    "# the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e09c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(): \n",
    "    inp = Input(shape=(100,100,3), name='input_image')\n",
    "    \n",
    "    # First block\n",
    "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
    "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
    "    \n",
    "    # Second block\n",
    "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
    "    \n",
    "    # Third block \n",
    "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
    "    \n",
    "    # Final embedding block\n",
    "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
    "    f1 = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd4182",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(tf.keras.layers.Layer):\n",
    "    \n",
    "    # Init method - inheritance\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_siamese_model(): \n",
    "    \n",
    "    # Anchor image input in the network\n",
    "    input_image = Input(name='input_img', shape=(100,100,3))\n",
    "    \n",
    "    # Validation image in the network \n",
    "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
    "    \n",
    "    # Combine siamese distance components\n",
    "    embedding = make_embedding()\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
    "    \n",
    "    # Classification layer \n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "    \n",
    "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = make_siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473b3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d29a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee73d399",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6d74bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(batch):\n",
    "    \n",
    "    # Record all of our operations \n",
    "    with tf.GradientTape() as tape:     \n",
    "        # Get anchor and positive/negative image\n",
    "        X = batch[:2]\n",
    "        # Get label\n",
    "        y = batch[2]\n",
    "        \n",
    "        # Forward pass\n",
    "        yhat = siamese_model(X, training=True)\n",
    "        # Calculate loss\n",
    "        loss = binary_cross_loss(y, yhat)\n",
    "    print(loss)\n",
    "        \n",
    "    # Calculate gradients\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    \n",
    "    # Calculate updated weights and apply to siamese model\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "        \n",
    "    # Return loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce0435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b3941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    # Loop through epochs\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        # Creating a metric object \n",
    "        r = Recall()\n",
    "        p = Precision()\n",
    "        \n",
    "        # Loop through each batch\n",
    "        for idx, batch in enumerate(data):\n",
    "            # Run train step here\n",
    "            loss = train_step(batch)\n",
    "            yhat = siamese_model.predict(batch[:2])\n",
    "            r.update_state(batch[2], yhat)\n",
    "            p.update_state(batch[2], yhat) \n",
    "            progbar.update(idx+1)\n",
    "        print(loss.numpy(), r.result().numpy(), p.result().numpy())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e04c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(train_ds, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649f8d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save(os.path.join(os.getcwd() , 'model_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of test data\n",
    "test_input, test_val, y_true = val_ds.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d20b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = siamese_model.predict([test_input, test_val])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
