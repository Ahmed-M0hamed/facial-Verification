{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0f30f8b",
   "metadata": {},
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77c0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import os \n",
    "import matplotlib.pyplot as plt \n",
    "from torch.utils.data import Dataset , DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "from torchvision.io import read_image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d3a2ef",
   "metadata": {},
   "source": [
    "# custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26414c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset) : \n",
    "    def __init__(self , anchors_folder , images_folder ,label , transform = None  ): \n",
    "        self.anchors_folder = anchors_folder\n",
    "        self.images_folder  = images_folder \n",
    "        self.transform = transform \n",
    "        self.label = label\n",
    "        self.anchors_paths = os.listdir(os.path.join(os.getcwd() , 'data' , anchors_folder)) \n",
    "        self.images_paths = os.listdir(os.path.join(os.getcwd() , 'data' , images_folder))\n",
    "        self.anchors_paths = self.anchors_paths[:1500] \n",
    "        self.images_paths = self.images_paths[:1500]\n",
    "    def __len__(self ) : \n",
    "        return len(self.images_paths) \n",
    "    def __getitem__(self , idx ) : \n",
    "        anchor_image = read_image(os.path.join(os.getcwd() , 'data' , self.anchors_folder, self.anchors_paths[idx])) \n",
    "        image = read_image(os.path.join(os.getcwd() , 'data'  , self.images_folder, self.images_paths[idx]))\n",
    "        anchor_image = anchor_image / 255\n",
    "        image = image / 255\n",
    "        \n",
    "        if self.transform : \n",
    "            anchor_image = self.transform(anchor_image) \n",
    "            image = self.transform(image) \n",
    "        return anchor_image , image , self.label\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_data = CustomDataset('anchors' , 'positive'  , 1 ,transforms.Compose([Resize((100,100))]))\n",
    "negative_data = CustomDataset('anchors' , 'negative'  , 0 ,transforms.Compose([Resize((100,100))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91055b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "3000 * .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e47d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.ConcatDataset([positive_data  ,negative_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=16,\n",
    "                        shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d61cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set = torch.utils.data.random_split(data_loader, [ 150,38 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884b0b49",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6268cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1Dist(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "       \n",
    "    # Magic happens here - similarity calculation\n",
    "    def forward(self, input_embedding, validation_embedding):\n",
    "        return torch.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d275227",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedding(nn.Module) : \n",
    "    def __init__(self ) : \n",
    "        super().__init__()\n",
    "        self.b1 =  nn.Sequential(nn.Conv2d(3 , 64 , (10 ,10 ) ) \n",
    "                               , nn.ReLU()\n",
    "                               ,nn.MaxPool2d((2,2)) )\n",
    "        self.b2 =  nn.Sequential(nn.Conv2d(64 , 128 , (7 ,7 ) ) \n",
    "                               , nn.ReLU()\n",
    "                               ,nn.MaxPool2d((2,2)) )\n",
    "        self.b3 =  nn.Sequential(nn.Conv2d(128 , 128 , (4 ,4 ) ) \n",
    "                               , nn.ReLU()\n",
    "                               ,nn.MaxPool2d((2,2)) )\n",
    "        \n",
    "        self.b4 = nn.Sequential(nn.Conv2d(128 , 256 , (4 ,4 ) ) \n",
    "                               , nn.ReLU()\n",
    "                               ,nn.Flatten() )\n",
    "        \n",
    "        self.out = nn.Linear(6400 , 4096) \n",
    "        self.s = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self , x) : \n",
    "        x = self.b1(x)\n",
    "        x = self.b2(x)\n",
    "        x = self.b3(x)\n",
    "        x = self.b4(x)\n",
    "        x = self.s(self.out(x))\n",
    "        return x \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module): \n",
    "    def __init__(self) : \n",
    "        super().__init__()\n",
    "        self.embedding  = embedding()\n",
    "        self.distance = L1Dist()\n",
    "        self.out = nn.Linear(4096 , 1)\n",
    "        self.s = nn.Sigmoid()\n",
    "    def forward(self , x_1 , x_2)  : \n",
    "        return self.s(self.out(self.distance(self.embedding(x_1) , self.embedding(x_2))))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ba358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39598b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters() ,  lr = .0001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412806a6",
   "metadata": {},
   "source": [
    "# train step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a752efaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               dataloader: torch.utils.data.DataLoader, \n",
    "               loss_fn: torch.nn.Module, \n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    # Put model in train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Setup train loss and train accuracy values\n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    # Loop through data loader data batches\n",
    "    for batch, (anchors , images, labels ) in enumerate(dataloader):\n",
    "\n",
    "        # 1. Forward pass\n",
    "        y_pred = model(anchors , images)\n",
    "        y_pred = y_pred.type(torch.float).squeeze(-1)\n",
    "        # 2. Calculate  and accumulate loss\n",
    "        loss = loss_fn(y_pred, labels.type(torch.float))\n",
    "        train_loss += loss.item() \n",
    "\n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate and accumulate accuracy metric across all batches\n",
    "        y_pred_class = torch.round(y_pred)\n",
    "        train_acc += (y_pred_class == labels).sum().item()/len(y_pred)\n",
    "\n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    train_loss = train_loss / len(dataloader)\n",
    "    train_acc = train_acc / len(dataloader)\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2888250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module, \n",
    "              dataloader: torch.utils.data.DataLoader, \n",
    "              loss_fn: torch.nn.Module):\n",
    "    # Put model in eval mode\n",
    "    model.eval() \n",
    "    \n",
    "    # Setup test loss and test accuracy values\n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # Turn on inference context manager\n",
    "    with torch.inference_mode():\n",
    "        # Loop through DataLoader batches\n",
    "        for batch, (anchors , images, labels) in enumerate(dataloader):\n",
    "            # 1. Forward pass\n",
    "            test_pred_logits = model(anchors  , images)\n",
    "            test_pred_logits = test_pred_logits.type(torch.float).squeeze(-1)\n",
    "            # 2. Calculate  and accumulate loss\n",
    "            loss = loss_fn(test_pred_logits, labels.type(torch.float))\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Calculate and accumulate accuracy\n",
    "            test_pred_labels = test_pred_logits.round()\n",
    "            test_acc += ((test_pred_labels == labels).sum().item()/len(test_pred_labels))\n",
    "            \n",
    "    # Adjust metrics to get average loss and accuracy per batch \n",
    "    test_loss = test_loss / len(dataloader)\n",
    "    test_acc = test_acc / len(dataloader)\n",
    "    return test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fdfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Take in various parameters required for training and test steps\n",
    "def train(model: torch.nn.Module, \n",
    "          train_dataloader: torch.utils.data.DataLoader, \n",
    "          test_dataloader: torch.utils.data.DataLoader, \n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
    "          epochs: int = 5):\n",
    "    \n",
    "    # 2. Create empty results dictionary\n",
    "    results = {\"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"test_loss\": [],\n",
    "        \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    # 3. Loop through training and testing steps for a number of epochs\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=train_dataloader,\n",
    "                                           loss_fn=loss_fn,\n",
    "                                           optimizer=optimizer)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "            dataloader=test_dataloader,\n",
    "            loss_fn=loss_fn)\n",
    "        \n",
    "        # 4. Print out what's happening\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 5. Update results dictionary\n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    # 6. Return the filled results at the end of the epochs\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02411635",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_results = train(model=model, \n",
    "                        train_dataloader=train_loader,\n",
    "                        test_dataloader=val_loader,\n",
    "                        optimizer=optim,\n",
    "                        loss_fn=loss_fn, \n",
    "                        epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,os.path.join(os.getcwd() , 'pytorch_model.pth'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
